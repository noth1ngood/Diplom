{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "13ae8d6e",
   "metadata": {},
   "source": [
    "# Практикуемся в ВКР"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2582f0ed",
   "metadata": {},
   "source": [
    "## 1. Импорт библиотек "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "49e2d896",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/nnn/anaconda3/lib/python3.11/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: 'dlopen(/Users/nnn/anaconda3/lib/python3.11/site-packages/torchvision/image.so, 0x0006): Symbol not found: __ZN3c1017RegisterOperatorsD1Ev\n",
      "  Referenced from: <F263C8ED-23C1-35DD-BD33-2CD667C0ED1D> /Users/nnn/anaconda3/lib/python3.11/site-packages/torchvision/image.so\n",
      "  Expected in:     <F8622D92-25A9-3A61-A089-C917FDA36C1B> /Users/nnn/anaconda3/lib/python3.11/site-packages/torch/lib/libtorch_cpu.dylib'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import os\n",
    "from PIL import Image\n",
    "from scipy.signal import convolve2d\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "import torch, torchvision\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3297a17c",
   "metadata": {},
   "source": [
    "## 2. Загрузка данных "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17b42624",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "916d0f61",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████| 5038/5038 [00:06<00:00, 819.85it/s]\n"
     ]
    }
   ],
   "source": [
    "clear_data_path = 'data/clear_data'\n",
    "stego_data_path = 'data/stego_data'\n",
    "\n",
    "pictures_names = os.listdir('data/clear_data')\n",
    "\n",
    "for name in tqdm(pictures_names):\n",
    "    if not name.startswith('.'):\n",
    "        payload = 0.4               \n",
    "        params = -1              \n",
    "        \n",
    "        filename = os.path.join(clear_data_path, name)\n",
    "        cover = Image.open(filename)\n",
    "        cover = cover.resize((256,256))\n",
    "        \n",
    "        cover = cover.convert('L')\n",
    "        cover.save(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfeb6f9c",
   "metadata": {},
   "source": [
    "## 4. Структурирование данных "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5b874efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "clear_paths = list(map(lambda x: os.path.join(clear_data_path, x), os.listdir(clear_data_path)))\n",
    "pictures_clear_df = pd.DataFrame({\n",
    "    \"picture_link\": clear_paths,\n",
    "    \"is_changed\": np.zeros(len(clear_paths), dtype=int)\n",
    "})\n",
    "\n",
    "stego_paths = list(map(lambda x: os.path.join(stego_data_path, x), os.listdir(stego_data_path)))\n",
    "pictures_graphed_df = pd.DataFrame({\n",
    "    \"picture_link\": stego_paths,\n",
    "    \"is_changed\": np.ones(len(stego_paths), dtype=int)\n",
    "})\n",
    "\n",
    "data = shuffle(pd.concat([pictures_clear_df, pictures_graphed_df]))\n",
    "data.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "9a184301",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data[data['picture_link'] != \"data/clear_data/.DS_Store\"]\n",
    "data = data[data['picture_link'] != \"data/stego_data/.DS_Store\"]\n",
    "data.to_csv(\"data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "00d2fea2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(Dataset):\n",
    "    \"\"\"Описантельный класс датасета для удобной работы с ним\"\"\"\n",
    "\n",
    "    def __init__(self, csv_file=None, transform=None):\n",
    "        \"\"\"\n",
    "            Args:\n",
    "                csv_file (string): Путь к csv файлу с разметкой\n",
    "                transform (callable, optional): Опционально, трансформации применяемые к картинкам\n",
    "        \"\"\"\n",
    "        \n",
    "        self.annotations = pd.read_csv(csv_file)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return self.annotations.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        img_info = self.annotations.iloc[idx]\n",
    "        image = io.imread(img_info[0])\n",
    "        label = img_info[1]\n",
    "        \n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "                \n",
    "        sample = torch.tensor([image], dtype=torch.float32), label\n",
    "\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b30dc7fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([transforms.ToPILImage(), transforms.Resize((256, 256)), transforms.ToTensor()])\n",
    "train_dataset = Dataset(csv_file='data.csv')\n",
    "\n",
    "train_part = np.arange(0, int(len(train_dataset) * 0.7))\n",
    "val_part = np.arange(int(len(train_dataset) * 0.7), int(len(train_dataset) * 0.9))\n",
    "test_part = np.arange(int(len(train_dataset) * 0.9), len(train_dataset))\n",
    "\n",
    "sampler_to_train = torch.utils.data.SubsetRandomSampler(train_part)\n",
    "sampler_to_val = torch.utils.data.SubsetRandomSampler(val_part)\n",
    "sampler_to_test = torch.utils.data.SubsetRandomSampler(test_part)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler_to_train) \n",
    "val_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler_to_val)\n",
    "test_loader = DataLoader(train_dataset, batch_size=64, sampler=sampler_to_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ba1d734",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
